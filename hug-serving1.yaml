apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "hug-serving1"
  namespace: kserve-test
spec:
  predictor:
    model:
      modelFormat:
        name: pytorch
      storageUri: "docker.io/joshbottum/flan-t5-translation:latest"

